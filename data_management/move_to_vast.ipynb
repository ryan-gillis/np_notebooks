{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import np_tools\n",
    "import pathlib\n",
    "import npc_lims\n",
    "import npc_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = pathlib.Path(\n",
    "    '//allen/programs/mindscope/workgroups/dynamicrouting/PilotEphys/Task 2 pilot'\n",
    ")\n",
    "\n",
    "MIN_TB_TO_MOVE = 5\n",
    "\n",
    "sessions_to_skip = sorted(\n",
    "    s.id for s in npc_lims.get_session_info()\n",
    "    if \"https://github.com/AllenInstitute/npc_lims/issues/5\" in s.issues\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_to_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures    \n",
    "import dataclasses\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Info:\n",
    "    size: float\n",
    "    path: pathlib.Path\n",
    "    \n",
    "def get_folder_info(folder):\n",
    "    if not folder.is_dir():\n",
    "        return None\n",
    "    return Info(\n",
    "        size=np_tools.dir_size_gb(folder),\n",
    "        path=folder,\n",
    "    )\n",
    "    \n",
    "dirs = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for folder in executor.map(get_folder_info, SRC.iterdir()):\n",
    "        if folder:\n",
    "            dirs.append(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures    \n",
    "import dataclasses\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Info:\n",
    "    size: float\n",
    "    path: pathlib.Path\n",
    "    date: str\n",
    "    session: npc_session.SessionRecord\n",
    "    \n",
    "def get_session_dir_info(session_dir):\n",
    "    if not session_dir.is_dir():\n",
    "        return None\n",
    "    try:\n",
    "        session = npc_session.SessionRecord(session_dir)\n",
    "    except:\n",
    "        return None\n",
    "    if session in sessions_to_skip:\n",
    "        return None\n",
    "    return Info(\n",
    "        size=np_tools.dir_size_gb(session_dir),\n",
    "        path=session_dir,\n",
    "        date=session.date,\n",
    "        session=session,\n",
    "    )\n",
    "    \n",
    "dirs = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for session in executor.map(get_session_dir_info, SRC.iterdir()):\n",
    "        if session:\n",
    "            dirs.append(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys_sessions = sorted((d for d in dirs if d.size >= 10 and d.size >= 1000), key=lambda d: d.date)\n",
    "move_sessions = []\n",
    "move_size = 0\n",
    "for d in ephys_sessions:\n",
    "    move_size += d.size\n",
    "    move_sessions.append(d)\n",
    "    if move_size >= MIN_TB_TO_MOVE * 1024:\n",
    "        break\n",
    "sum(t.size for t in move_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "scratch = pathlib.Path('//allen/programs/mindscope/workgroups/dynamicrouting/ben/vast_transfers')\n",
    "scratch.mkdir(parents=True, exist_ok=True)\n",
    "dt = datetime.datetime.now()\n",
    "DEST = pathlib.Path('//allen/aind/scratch/dynamic-routing/Task 2 pilot')\n",
    "\n",
    "def get_file_manifest(info: Info) -> list[pathlib.Path]:\n",
    "    return list(info.path.rglob('*'))\n",
    "\n",
    "def write_manifest(info: Info) -> None:   \n",
    "    get_manifest_path(info).write_text(\n",
    "        '\\n'.join(p.relative_to(SRC).as_posix() for p in get_file_manifest(info)),\n",
    "        newline='\\n',\n",
    "    )\n",
    "\n",
    "def get_hpc_output_path(info: Info) -> pathlib.Path:\n",
    "    return scratch / f'{info.session}_{dt:%Y-%m-%d_%H%M}.log'\n",
    "\n",
    "def get_manifest_path(info: Info) -> pathlib.Path:   \n",
    "    p = get_hpc_output_path(info).with_suffix('.txt')\n",
    "    p.touch(exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def get_log_path(info: Info) -> pathlib.Path:\n",
    "    p = get_hpc_output_path(info)\n",
    "    p.touch(exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def get_shell_script_path(info: Info) -> pathlib.Path:\n",
    "    p = get_hpc_output_path(info).with_suffix('.sh')\n",
    "    p.touch(exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def get_rsync_cmd(info: Info) -> str:\n",
    "    src = info.path.as_posix()\n",
    "    dest = DEST.as_posix()\n",
    "    rsync_cmd = f'rsync -Larv --remove-source-files --log-file={get_log_path(info).as_posix()} --files-from={get_manifest_path(info).as_posix()} \"{src}\" \"{dest}\"'\n",
    "    # -a archive mode\n",
    "    # -r recursive (for dirs)\n",
    "    # -v verbose\n",
    "    # -L copy the data that symlinks point to\n",
    "    # --remove-source-files deletes source files after copying, but not dirs\n",
    "    return rsync_cmd\n",
    "\n",
    "def get_shell_script_cmd(info: Info) -> str:\n",
    "    script = f\"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=npexp_to_incoming                        # Job name\n",
    "#SBATCH --mail-type=FAIL                                    # Mail events (NONE, BEGIN, END, FAIL, ALL)\n",
    "#SBATCH --mail-user=ben.hardcastle@alleninstitute.org       # Where to send mail  \n",
    "#SBATCH --ntasks=1                                          # Run on a single CPU\n",
    "#SBATCH --mem=4gb                                           # Job memory request (per node)\n",
    "#SBATCH --time=20:00:00                                     # Time limit hrs:min:sec\n",
    "#SBATCH --output=dynamicrouting_to_vast%j.log               # Standard output and error log\n",
    "#SBATCH --partition braintv                                 # Partition used for processing\n",
    "#SBATCH --tmp=100M                                          # Request the amount of space your jobs needs on /scratch/fast\n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "echo 'Running rsync job on a single thread'\n",
    "\n",
    "{get_rsync_cmd(info)}\n",
    "\n",
    "date\n",
    "\"\"\"\n",
    "    return script\n",
    "\n",
    "def write_shell_script(info: Info) -> None:\n",
    "    get_shell_script_path(info).write_text(get_shell_script_cmd(info), newline='\\n') \n",
    "    # if writing on Windows, newline==\\r\\n by default, which isn't compatible with bash on linux\n",
    "\n",
    "def submit_job(info: Info) -> None:\n",
    "    with np_tools.hpc as ssh:\n",
    "        ssh.run(f'sbatch {get_shell_script_path(info).as_posix()}')\n",
    "\n",
    "def process(info: Info) -> None:\n",
    "    write_manifest(info)\n",
    "    write_shell_script(info)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for future in concurrent.futures.as_completed([executor.submit(process, t) for t in ephys_sessions]):\n",
    "        _ = future.result() # wait for completion / handle exceptions\n",
    "\n",
    "for info in ephys_sessions:\n",
    "    submit_job(info) # submit jobs to HPC in series to avoid overloading the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shell_script_cmd(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
