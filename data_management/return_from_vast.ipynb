{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import np_tools\n",
    "import pathlib\n",
    "import npc_lims\n",
    "import npc_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = pathlib.Path('//allen/aind/scratch/dynamic-routing/Task 2 pilot')\n",
    "DEST = pathlib.Path('//allen/programs/mindscope/workgroups/dynamicrouting/PilotEphys/Task 2 pilot')\n",
    "\n",
    "MAX_TB_TO_MOVE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures    \n",
    "import dataclasses\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Info:\n",
    "    size: float\n",
    "    path: pathlib.Path\n",
    "    \n",
    "def get_session_dir_info(session_dir):\n",
    "    if not session_dir.is_dir():\n",
    "        return None\n",
    "    return Info(\n",
    "        size=np_tools.dir_size_gb(session_dir),\n",
    "        path=session_dir,\n",
    "    )\n",
    "    \n",
    "dirs = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for session in executor.map(get_session_dir_info, SRC.iterdir()):\n",
    "        if session:\n",
    "            dirs.append(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5227.500000000004"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_sessions = []\n",
    "move_size = 0\n",
    "for d in dirs:\n",
    "    if d.size == 0:\n",
    "        continue\n",
    "    move_size += d.size\n",
    "    move_sessions.append(d)\n",
    "    if MAX_TB_TO_MOVE is not None and move_size >= MAX_TB_TO_MOVE * 1024:\n",
    "        break\n",
    "sum(t.size for t in move_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 22041515\n",
      "Submitted batch job 22041516\n",
      "Submitted batch job 22041517\n",
      "Submitted batch job 22041518\n",
      "Submitted batch job 22041519\n",
      "Submitted batch job 22041520\n",
      "Submitted batch job 22041521\n",
      "Submitted batch job 22041522\n",
      "Submitted batch job 22041523\n",
      "Submitted batch job 22041524\n",
      "Submitted batch job 22041525\n",
      "Submitted batch job 22041526\n",
      "Submitted batch job 22041527\n",
      "Submitted batch job 22041528\n",
      "Submitted batch job 22041529\n",
      "Submitted batch job 22041530\n",
      "Submitted batch job 22041531\n",
      "Submitted batch job 22041532\n",
      "Submitted batch job 22041533\n",
      "Submitted batch job 22041534\n",
      "Submitted batch job 22041535\n",
      "Submitted batch job 22041536\n",
      "Submitted batch job 22041537\n",
      "Submitted batch job 22041538\n",
      "Submitted batch job 22041539\n",
      "Submitted batch job 22041540\n",
      "Submitted batch job 22041541\n",
      "Submitted batch job 22041542\n",
      "Submitted batch job 22041543\n",
      "Submitted batch job 22041640\n",
      "Submitted batch job 22041647\n",
      "Submitted batch job 22041648\n",
      "Submitted batch job 22041649\n",
      "Submitted batch job 22041650\n",
      "Submitted batch job 22041651\n",
      "Submitted batch job 22041652\n",
      "Submitted batch job 22041653\n",
      "Submitted batch job 22041654\n",
      "Submitted batch job 22041655\n",
      "Submitted batch job 22041658\n",
      "Submitted batch job 22041659\n",
      "Submitted batch job 22041661\n",
      "Submitted batch job 22041662\n",
      "Submitted batch job 22041663\n",
      "Submitted batch job 22041751\n",
      "Submitted batch job 22041754\n",
      "Submitted batch job 22041755\n",
      "Submitted batch job 22041756\n",
      "Submitted batch job 22041757\n",
      "Submitted batch job 22041758\n",
      "Submitted batch job 22041759\n",
      "Submitted batch job 22041760\n",
      "Submitted batch job 22041761\n",
      "Submitted batch job 22041769\n",
      "Submitted batch job 22041770\n",
      "Submitted batch job 22041839\n",
      "Submitted batch job 22041848\n",
      "Submitted batch job 22041849\n",
      "Submitted batch job 22041853\n",
      "Submitted batch job 22041875\n",
      "Submitted batch job 22041888\n",
      "Submitted batch job 22041889\n",
      "Submitted batch job 22041890\n",
      "Submitted batch job 22041891\n",
      "Submitted batch job 22041892\n",
      "Submitted batch job 22041893\n",
      "Submitted batch job 22041894\n",
      "Submitted batch job 22041965\n",
      "Submitted batch job 22041966\n",
      "Submitted batch job 22041967\n",
      "Submitted batch job 22041974\n",
      "Submitted batch job 22041978\n",
      "Submitted batch job 22041981\n",
      "Submitted batch job 22041983\n",
      "Submitted batch job 22041993\n",
      "Submitted batch job 22041994\n",
      "Submitted batch job 22041995\n",
      "Submitted batch job 22041996\n",
      "Submitted batch job 22042066\n",
      "Submitted batch job 22042067\n",
      "Submitted batch job 22042077\n",
      "Submitted batch job 22042078\n",
      "Submitted batch job 22042079\n",
      "Submitted batch job 22042086\n",
      "Submitted batch job 22042087\n",
      "Submitted batch job 22042088\n",
      "Submitted batch job 22042089\n",
      "Submitted batch job 22042096\n",
      "Submitted batch job 22042100\n",
      "Submitted batch job 22042101\n",
      "Submitted batch job 22042102\n",
      "Submitted batch job 22042181\n",
      "Submitted batch job 22042182\n",
      "Submitted batch job 22042183\n",
      "Submitted batch job 22042190\n",
      "Submitted batch job 22042191\n",
      "Submitted batch job 22042192\n",
      "Submitted batch job 22042197\n",
      "Submitted batch job 22042198\n",
      "Submitted batch job 22042199\n",
      "Submitted batch job 22042201\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "scratch = pathlib.Path('//allen/programs/mindscope/workgroups/dynamicrouting/ben/vast_transfers')\n",
    "scratch.mkdir(parents=True, exist_ok=True)\n",
    "dt = datetime.datetime.now()\n",
    "\n",
    "def get_file_manifest(info: Info) -> list[pathlib.Path]:\n",
    "    return list(info.path.rglob('*'))\n",
    "\n",
    "def write_manifest(info: Info) -> None:   \n",
    "    get_manifest_path(info).write_text(\n",
    "        '\\n'.join(p.relative_to(SRC).as_posix() for p in get_file_manifest(info)),\n",
    "        newline='\\n',\n",
    "    )\n",
    "\n",
    "def get_hpc_output_path(info: Info) -> pathlib.Path:\n",
    "    return scratch / f'{info.path.name}_{dt:%Y-%m-%d_%H%M}.log'\n",
    "\n",
    "def get_manifest_path(info: Info) -> pathlib.Path:   \n",
    "    p = get_hpc_output_path(info).with_suffix('.txt')\n",
    "    p.touch(exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def get_log_path(info: Info) -> pathlib.Path:\n",
    "    p = get_hpc_output_path(info)\n",
    "    p.touch(exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def get_shell_script_path(info: Info) -> pathlib.Path:\n",
    "    p = get_hpc_output_path(info).with_suffix('.sh')\n",
    "    p.touch(exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def get_rsync_cmd(info: Info) -> str:\n",
    "    src = SRC.as_posix()#.replace('//', '/') # rsync doesn't like double slashes\n",
    "    dest = DEST.as_posix()#.replace('//', '/')\n",
    "    rsync_cmd = f'rsync -Larv --remove-source-files --log-file={get_log_path(info).as_posix()} --files-from={get_manifest_path(info).as_posix()} \"{src}\" \"{dest}\"'\n",
    "    # -a archive mode\n",
    "    # -r recursive (for dirs)\n",
    "    # -v verbose\n",
    "    # -L copy the data that symlinks point to\n",
    "    # --remove-source-files deletes source files after copying, but not dirs\n",
    "    return rsync_cmd\n",
    "\n",
    "def get_shell_script_cmd(info: Info) -> str:\n",
    "    script = f\"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=npexp_to_incoming                        # Job name\n",
    "#SBATCH --mail-type=FAIL                                    # Mail events (NONE, BEGIN, END, FAIL, ALL)\n",
    "#SBATCH --mail-user=ben.hardcastle@alleninstitute.org       # Where to send mail  \n",
    "#SBATCH --ntasks=1                                          # Run on a single CPU\n",
    "#SBATCH --mem=8gb                                           # Job memory request (per node)\n",
    "#SBATCH --time=20:00:00                                     # Time limit hrs:min:sec\n",
    "#SBATCH --output=vast_to_dynamicrouting_%j.log              # Standard output and error log\n",
    "#SBATCH --partition braintv                                 # Partition used for processing\n",
    "#SBATCH --tmp=100M                                          # Request the amount of space your jobs needs on /scratch/fast\n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "echo 'Running rsync job on a single thread'\n",
    "\n",
    "{get_rsync_cmd(info)}\n",
    "\n",
    "date\n",
    "\"\"\"\n",
    "    return script\n",
    "\n",
    "def write_shell_script(info: Info) -> None:\n",
    "    get_shell_script_path(info).write_text(get_shell_script_cmd(info), newline='\\n') \n",
    "    # if writing on Windows, newline==\\r\\n by default, which isn't compatible with bash on linux\n",
    "\n",
    "def submit_job(info: Info) -> None:\n",
    "    with np_tools.hpc as ssh:\n",
    "        ssh.run(f'sbatch {get_shell_script_path(info).as_posix()}')\n",
    "\n",
    "def process(info: Info) -> None:\n",
    "    write_manifest(info)\n",
    "    write_shell_script(info)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for future in concurrent.futures.as_completed([executor.submit(process, t) for t in move_sessions]):\n",
    "        _ = future.result() # wait for completion / handle exceptions\n",
    "\n",
    "for info in move_sessions:\n",
    "    submit_job(info) # submit jobs to HPC in series to avoid overloading the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Info(size=44.3, path=WindowsPath('//allen/aind/scratch/dynamic-routing/Task 2 pilot/DRpilot_668755_20230829_surface_channels (2)'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('//allen/programs/mindscope/workgroups/dynamicrouting/ben/vast_transfers/741148_2024-10-18_2024-11-26_1032.txt')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_manifest_path(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shell_script_cmd(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
